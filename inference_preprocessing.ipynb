{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3072c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "SUPPORTED_EXTENSIONS = [\".zip\", \".tar.gz\", \".tar\", \".tgz\", \".7z\", \".egg\"]\n",
    "\n",
    "def get_output_path(zip_path):\n",
    "    zip_path = Path(zip_path)\n",
    "    if zip_path.name.endswith(\".tar.gz\") or zip_path.name.endswith(\".tgz\"):\n",
    "        name = zip_path.name.replace(\".tar.gz\", \"\").replace(\".tgz\", \"\")\n",
    "    elif zip_path.name.endswith(\".7z\") or zip_path.name.endswith(\".egg\"):\n",
    "        name = zip_path.name.replace(\".7z\", \"\").replace(\".egg\", \"\")\n",
    "    else:\n",
    "        name = zip_path.stem\n",
    "    return zip_path.parent / name\n",
    "\n",
    "def extract(zip_path):\n",
    "    zip_path = str(zip_path)\n",
    "    output_path = get_output_path(zip_path)\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"[오류] 파일 없음: {zip_path}\")\n",
    "        return\n",
    "\n",
    "    if output_path.exists():\n",
    "        print(f\"[스킵] 이미 압축 해제된 폴더 존재: {output_path}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        if zip_path.endswith(\".zip\"):\n",
    "            cmd = [\"unzip\", \"-o\", zip_path, \"-d\", str(output_path)]\n",
    "        elif zip_path.endswith(\".tar.gz\") or zip_path.endswith(\".tgz\"):\n",
    "            cmd = [\"tar\", \"-xzf\", zip_path, \"-C\", str(output_path)]\n",
    "        elif zip_path.endswith(\".tar\"):\n",
    "            cmd = [\"tar\", \"-xf\", zip_path, \"-C\", str(output_path)]\n",
    "        elif zip_path.endswith(\".7z\") or zip_path.endswith(\".egg\"):\n",
    "            cmd = [\"7z\", \"x\", zip_path, f\"-o{output_path}\"]\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 확장자\")\n",
    "\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(result.stderr.decode(\"utf-8\"))\n",
    "        print(f\"[완료] 압축 해제 성공: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        shutil.rmtree(output_path, ignore_errors=True)\n",
    "        print(f\"[실패] {zip_path} → {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58945d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "def extract_zip(zip_path):\n",
    "    zip_path = Path(zip_path)\n",
    "    \n",
    "    if not zip_path.exists():\n",
    "        print(f\"[오류] 파일 없음: {zip_path}\")\n",
    "        return None\n",
    "\n",
    "    if zip_path.suffix.lower() != \".zip\":\n",
    "        print(f\"[오류] 지원하지 않는 확장자: {zip_path.suffix}\")\n",
    "        return None\n",
    "\n",
    "    output_dir = zip_path.parent / zip_path.stem\n",
    "\n",
    "    if output_dir.exists():\n",
    "        print(f\"[스킵] 이미 존재: {output_dir}\")\n",
    "        return str(output_dir)\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "        print(f\"[완료] 압축 해제됨 → {output_dir}\")\n",
    "        return str(output_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"[실패] {zip_path} → {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3673148",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = extract_zip(r\"D:\\새 폴더 (2)\\add_data\\JLK_NCCT\\DCM_REQUEST_2025-07-23-05-16-58-465027_0.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import draw_overlay_cti\n",
    "from CT_Preprocessing import PreprocessingCTImage as pp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 경로 객체로 처리\n",
    "\n",
    "def get_jlk_summary_dirs(p: Path):\n",
    "    if not re.search(r'ICH|CTI|CTL|WMHC|CVL', str(p)):\n",
    "        return []\n",
    "    try:\n",
    "        return [\n",
    "            child.name\n",
    "            for child in p.iterdir()\n",
    "            if child.is_dir() and 'summary' in child.name.lower()\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"[오류] {p} → {e}\")\n",
    "        return []\n",
    "\n",
    "def join_jlk_full_paths(row):\n",
    "    if not isinstance(row['JLK_AI'], list):\n",
    "        return []\n",
    "    return [row['file'] / sub for sub in row['JLK_AI']]\n",
    "\n",
    "def normalize_to_8bit(array):\n",
    "    array = array.astype(np.float32)\n",
    "    array -= array.min()\n",
    "    array /= (array.max() + 1e-8)\n",
    "    array *= 255\n",
    "    return array.astype(np.uint8)\n",
    "\n",
    "def dicom_to_png(path, save_path):\n",
    "    ds = pydicom.dcmread(path)\n",
    "    arr = normalize_to_8bit(ds.pixel_array)\n",
    "    image = Image.fromarray(arr)\n",
    "    image.save(save_path)\n",
    "\n",
    "def convert_all_dicom_to_png(grouped_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for num, row in tqdm(grouped_df.iterrows(), total=len(grouped_df)):\n",
    "        patientID = row['patientID']\n",
    "        StudyDesc = row['StudyDesc'].split('. ')[-1]\n",
    "        SeriesDesc = row['SeriesDesc'].split('. ')[-1]\n",
    "        dir_path = os.path.join(output_dir, f\"{patientID}_{StudyDesc}_{SeriesDesc}\")\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        if \"NCCT\" in row['modality']: \n",
    "            non_mask(row['file'], dir_path)\n",
    "        else:\n",
    "            for idx, f in enumerate(row['JLK_AI_full_dcm']):\n",
    "                sub_path = os.path.join(dir_path, row['modality'])\n",
    "                os.makedirs(sub_path, exist_ok=True)\n",
    "                fname = os.path.basename(f).replace(\".dcm\", f\"_{idx}.png\")\n",
    "                save_path = os.path.join(sub_path, fname)\n",
    "                dicom_to_png(f, save_path)\n",
    "\n",
    "def non_mask(dcm_path, dir_path):\n",
    "    image_sitk = pp.read_dicom(dcm_path)\n",
    "    image_np = pp.to_numpy(image_sitk)\n",
    "    total_region = np.zeros_like(image_np)\n",
    "    draw_fig,_,_,_ = draw_overlay_cti(image_np,total_region)\n",
    "    draw_fig = draw_fig.astype(np.uint8)[:, :, :3]\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(draw_fig)\n",
    "    plt.axis('off')  # 축 제거\n",
    "    plt.tight_layout()\n",
    "    non_mask_path = os.path.join(dir_path, \"Non_mask\")\n",
    "    os.makedirs(non_mask_path, exist_ok=True)\n",
    "    plt.savefig(f'{non_mask_path}\\\\non_mask.png', bbox_inches='tight', pad_inches=0, facecolor='black')\n",
    "\n",
    "def _collection_path(extract_path):\n",
    "    extract_path = Path(extract_path)  # 문자열이면 Path로 변환\n",
    "    paths = list(extract_path.glob(\"*/*/*/*/*\"))  # 5단계 하위 폴더 모두 수집\n",
    "\n",
    "    # DataFrame 구성\n",
    "    path_ = pd.DataFrame(paths, columns=['file'])\n",
    "\n",
    "    # 메타 정보 추출\n",
    "    path_['patientID'] = path_['file'].apply(lambda x: x.parts[-4])\n",
    "    path_['StudyDesc'] = path_['file'].apply(lambda x: x.parts[-3])\n",
    "    path_['SeriesDesc'] = path_['file'].apply(lambda x: x.parts[-2])\n",
    "    path_['modality'] = path_['file'].apply(lambda x: x.parts[-1])\n",
    "    path_['JLK_AI'] = path_['file'].apply(get_jlk_summary_dirs)\n",
    "    path_['JLK_AI_full'] = path_.apply(join_jlk_full_paths, axis=1)\n",
    "    path_['JLK_AI_full_dcm'] = path_['JLK_AI_full'].apply(\n",
    "        lambda folders: list(\n",
    "            chain.from_iterable(folder.rglob(\"*.dcm\") for folder in folders)\n",
    "        ) if isinstance(folders, list) else []\n",
    "    )\n",
    "    return path_\n",
    "\n",
    "\n",
    "\n",
    "def process_row(row, output_dir):\n",
    "    patientID = row['patientID']\n",
    "    StudyDesc = row['StudyDesc'].split('. ')[-1]\n",
    "    SeriesDesc = row['SeriesDesc'].split('. ')[-1]\n",
    "    dir_path = os.path.join(output_dir, f\"{patientID}_{StudyDesc}_{SeriesDesc}\")\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    if \"NCCT\" in row['modality']: \n",
    "        non_mask(row['file'], dir_path)\n",
    "    else:\n",
    "        for idx, f in enumerate(row['JLK_AI_full_dcm']):\n",
    "            sub_path = os.path.join(dir_path, row['modality'])\n",
    "            os.makedirs(sub_path, exist_ok=True)\n",
    "            fname = os.path.basename(f).replace(\".dcm\", f\"_{idx}.png\")\n",
    "            save_path = os.path.join(sub_path, fname)\n",
    "            dicom_to_png(f, save_path)\n",
    "\n",
    "def convert_all_dicom_to_png_parallel(grouped_df, output_dir, max_workers=8):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    futures = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for _, row in grouped_df.iterrows():\n",
    "            futures.append(executor.submit(process_row, row, output_dir))\n",
    "\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures)):\n",
    "            pass  # 결과값을 저장할 필요 없고, 완료 여부만 추적함\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "from typing import Optional\n",
    "def pil_to_base64(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    patientId: str = Field(..., description=\"환자 고유 식별자\")\n",
    "    gender: str = Field(..., description=\"성별(Male/Female/Other 등)\")\n",
    "    age: int = Field(..., description=\"나이 (단위: 년)\")\n",
    "    imagingModalities: List[str] = Field(..., description=\"영상 촬영 모달리티 리스트 (예: ['NCCT', 'CTA', 'CTP'])\")\n",
    "    scanTimestamp: str = Field(..., description=\"스캔 시각 (ISO8601 형식)\")\n",
    "\n",
    "class ActionableRecommendation(BaseModel):\n",
    "    primary: str = Field(..., description=\"첫 번째 주요 권고\")\n",
    "    secondary: str = Field(..., description=\"추가적 권고\")\n",
    "    justification: str = Field(..., description=\"권고의 근거\")\n",
    "\n",
    "class Interpretation(BaseModel):\n",
    "    primaryDiagnosis: str = Field(..., description=\"주 진단 (영문)\")\n",
    "    pathophysiologicalSynopsis: str = Field(..., description=\"병태생리학적 해설(영문)\")\n",
    "    aiCritique: str = Field(..., description=\"AI 분석 결과의 비판적 평가 및 한계\")\n",
    "    actionableRecommendation: ActionableRecommendation = Field(..., description=\"권고사항\")\n",
    "\n",
    "class ImagingReport(BaseModel):\n",
    "    patientInfo: PatientInfo\n",
    "    interpretation: Interpretation\n",
    "def safe_load_image(image_path: str) -> Optional[str]:\n",
    "    if not os.path.exists(image_path):\n",
    "        logging.warning(f\"이미지 파일이 존재하지 않음: {image_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        return f\"data:image/png;base64,{pil_to_base64(image_path)}\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"이미지 변환 실패: {image_path} - {e}\")\n",
    "        return None\n",
    "    \n",
    "def JLK_ICH(mask_path: str,path: str) -> Optional[str]:\n",
    "    try:\n",
    "\n",
    "        content_blocks = []\n",
    "\n",
    "        desc_masked = (\n",
    "            \"Summary_0000_0 : JLK ICH는 비조영 CT에서 모든 유형의 뇌출혈을 탐지하는 AI 알고리즘입니다. 뇌출혈 의심 영역은 붉은색 마스크로 표시되며, 환자 단위의 뇌출혈 확률값과 전체 뇌영역에서의 뇌출혈 부피 정보가 함께 제공됩니다.\"\n",
    "        )\n",
    "        img_masked = safe_load_image(f'{path}/Summary_0000_0.png')\n",
    "        if img_masked:\n",
    "            content_blocks.append({\"type\": \"input_text\", \"text\": desc_masked})\n",
    "            content_blocks.append({\"type\": \"input_image\", \"image_url\": img_masked})\n",
    "\n",
    "        desc_nomask = (\n",
    "            \"Summary_0000_0_non_mask : Summary_0000_0과 동일한 영상이며, 붉은색 마스크를 제거한 버전입니다. (정확한 비교를 위해 mask만 제외되었습니다.)\"\n",
    "        )\n",
    "        img_nomask = safe_load_image(f'{mask_path}/non_mask.png')\n",
    "        if img_nomask:\n",
    "            content_blocks.append({\"type\": \"input_text\", \"text\": desc_nomask})\n",
    "            content_blocks.append({\"type\": \"input_image\", \"image_url\": img_nomask})\n",
    "\n",
    "        if not content_blocks:\n",
    "            logging.error(\"유효한 이미지가 없어 요청을 수행할 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4.1\",\n",
    "            prompt={\n",
    "                \"id\": \"pmpt_687ee31179fc819091e852e25eaca6c20399e215f5db1fab\",\n",
    "                \"version\": \"2\"\n",
    "            },\n",
    "            input=[{\"role\": \"user\", \"content\": content_blocks}],\n",
    "            reasoning={},\n",
    "            max_output_tokens=8192,\n",
    "            store=True,\n",
    "            text_format=ImagingReport,\n",
    "        )\n",
    "\n",
    "        if not hasattr(response, 'output_parsed'):\n",
    "            logging.error(\"output_parsed 항목이 응답에 존재하지 않음\")\n",
    "            return None\n",
    "\n",
    "        return response.output_parsed.model_dump_json(indent=2)\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"JLK_ICH 실행 중 오류 발생: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = extract_zip(r\"D:\\새 폴더 (2)\\add_data\\JLK_NCCT\\DCM_REQUEST_2025-07-23-05-16-58-465027_0.zip\")\n",
    "collection_path = _collection_path(extract_path)\n",
    "convert_all_dicom_to_png_parallel(collection_path, Path(r\"D:\\새 폴더 (2)\\add_data\\test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfd276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non_mask 없음: D:\\새 폴더 (2)\\add_data\\test\\DE-06495-2_Head^00_Brain_Pre_Seq (Adult)_Pre 4.0 Hr40\n",
      "Non_mask 없음: D:\\새 폴더 (2)\\add_data\\test\\DE-07205-1_Vascular^01_Head_Angio_Multi (Adult)_DSAnc DSA pre 4.0 Hr40\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(r'D:\\새 폴더 (2)\\add_data\\test')\n",
    "first_level = list(path.glob('*'))\n",
    "ich_result = []\n",
    "for item in first_level:\n",
    "    if item.is_dir():\n",
    "        non_mask_dir = item / 'Non_mask'\n",
    "        if non_mask_dir.exists() and any(non_mask_dir.glob('*')):\n",
    "            CTL_dir = next((p for p in item.glob('*') if p.is_dir() and 'CTL' in p.name), None)\n",
    "            CTI_dir = next((p for p in item.glob('*') if p.is_dir() and 'CTI' in p.name), None)\n",
    "            WMHC_dir = next((p for p in item.glob('*') if p.is_dir() and 'WMHC' in p.name), None)\n",
    "            ICH_dir = next((p for p in item.glob('*') if p.is_dir() and 'ICH' in p.name), None)\n",
    "            ich_result.append(JLK_ICH(non_mask_dir, ICH_dir))\n",
    "        else:\n",
    "            print(\"Non_mask 없음:\", item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9413db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/새 폴더 (2)/add_data/test/HC-04189-1_Head^00_BrainRoutine (Adult)_Brain 3.0 MPR ax iMAR/AI JLK-CTL 2.2.6.1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTL_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9d5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289550bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c30a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTLdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da54b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a010d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e40e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4697b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b13e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef546a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\\\'.join(dcm_path.split('\\\\')[:-1])+\"\\\\Non_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_.file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = r'D:\\새 폴더 (2)\\add_data\\ncct_raw'\n",
    "for i in path_[path_['modality'].str.contains('NCCT')].file:\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.isfile(i):\n",
    "        shutil.copy2(i, dst_dir)\n",
    "    elif os.path.isdir(i):\n",
    "        dst_name = os.path.join(dst_dir, os.path.basename(i))\n",
    "        if not os.path.exists(dst_name):  # 이미 존재하면 에러 방지\n",
    "            shutil.copytree(i, dst_name)\n",
    "    else:\n",
    "        print(f\"❌ 복사 실패 (파일도 폴더도 아님): {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fff6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JLK Solution Detail'] = df['path'].str.split('\\\\').str[8].str.split('\\d+\\.\\s').str[-1]\n",
    "df['JLK Solution Detail'] = df['JLK Solution Detail'].str.replace(r'\\bJLK[\\s_]+', 'JLK-', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b36ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
